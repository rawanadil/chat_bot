import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from difflib import get_close_matches
import nltk
import random
import os
from nltk.stem.isri import ISRIStemmer

# ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù„Ù„Ø³ÙŠØ±ÙØ±)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')


# ----------------------------
# 1ï¸âƒ£ Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
# ----------------------------
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub("[Ø¥Ø£Ø¢]", "Ø§", text)
    text = re.sub("Ù‰", "ÙŠ", text)
    text = re.sub("Ø©", "Ù‡", text)
    stop_words = ['Ø´Ù†Ùˆ', 'Ø´Ù„ÙˆÙ†', 'Ù‡Ù„', 'ÙÙŠ', 'Ù…Ù†', 'Ø¹Ù„Ù‰', 'Ø§Ù„ÙŠ', 'Ù‡ÙˆÙ‡', 'Ù‡ÙŠ', 'Ù…Ø§', 'Ù‡Ø°Ø§', 'Ù„Ùˆ']
    words = text.split()
    cleaned_words = [w for w in words if w not in stop_words]
    return " ".join(cleaned_words)


# ----------------------------
# 2ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ----------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
df_training = pd.read_csv(os.path.join(BASE_DIR, 'qustion.csv'), encoding='utf-8-sig')
df_departments = pd.read_csv(os.path.join(BASE_DIR, 'departments_utf8_bom.csv'), encoding='utf-8-sig')

df_training['Clean_Question'] = df_training['Question'].apply(clean_text)

# ----------------------------
# 3ï¸âƒ£ Ù†Ù…ÙˆØ°Ø¬ ML
# ----------------------------
model = Pipeline([
    ('vectorizer', TfidfVectorizer()),
    ('classifier', LogisticRegression(max_iter=500))
])

X = df_training['Clean_Question']
y = df_training['Intent']
model.fit(X, y)

# ----------------------------
# 4ï¸âƒ£ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
# ----------------------------
department_keywords = {
    "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¹Ù…Ø§Ø±Ø©": [
        "Ø§Ù„Ø¹Ù…Ø§Ø±Ù‡", "Ø¹Ù…Ø§Ø±Ø©", "Ù…Ø¹Ù…Ø§Ø±ÙŠ", "Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠ", "Ø¨Ù†Ø§Ø¡", "ØªØµÙ…ÙŠÙ… Ø¯Ø§Ø®Ù„ÙŠ",
        "Ø®Ø±Ø§Ø¦Ø·", "ØªØµØ§Ù…ÙŠÙ…", "architecture"
    ],
    "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": [
        "Ø°ÙƒØ§Ø¡", "Ø§Ù„Ø°ÙƒØ§Ø¡", "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "AI", "Ø¨Ø±Ù…Ø¬Ø©", "ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©",
        "machine learning", "Ø±ÙˆØ¨ÙˆØª", "Ø£Ù†Ø¸Ù…Ø© Ø°ÙƒÙŠØ©"
    ],
    "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ": [
        "Ø§Ù…Ù†", "Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "Ø§Ù„Ø£Ù…Ù†", "Ø§Ù„Ø§Ù…Ù†", "Ø­Ù…Ø§ÙŠØ©", "network",
        "Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "cybersecurity", "firewall", "hack", "Ø§Ø®ØªØ±Ø§Ù‚"
    ],
    "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©": [
        "Ø­ÙˆØ³Ø¨Ø©", "Ù…ØªÙ†Ù‚Ù„Ø©", "Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©", "Ø­ÙˆØ³Ø¨Ù‡", "Ù…ÙˆØ¨Ø§ÙŠÙ„", "ØªØ·Ø¨ÙŠÙ‚Ø§Øª",
        "app", "mobile", "Ø¨Ø±Ù…Ø¬Ø© Ù…ÙˆØ¨Ø§ÙŠÙ„", "Android", "iOS"
    ],
    "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠ": [
        "ØªØµÙ…ÙŠÙ…", "Ø±Ù‚Ù…ÙŠ", "Ø§Ù„Ø±Ù‚Ù…ÙŠ", "ÙˆØ§Ø¬Ù‡Ø§Øª", "UI", "UX", "graphic",
        "Ø¬Ø±Ø§ÙÙŠÙƒ", "ØªØµÙ…ÙŠÙ… Ù…ÙˆØ§Ù‚Ø¹", "web design"
    ]
}


def get_department_from_text(text):
    text = text.lower()
    for dept, keywords in department_keywords.items():
        for kw in keywords:
            if kw.lower() in text:
                return dept
    for dept in df_departments["Department"]:
        if dept.lower() in text:
            return dept
    return None


def get_department_info(dept_name):
    row = df_departments[df_departments["Department"] == dept_name]
    if not row.empty:
        return row.iloc[0]
    return None


def get_random_suggestion(dept_name, df_training, state):
    related = df_training[df_training['Question'].apply(
        lambda x: dept_name.lower().split()[-1] in x.lower() if pd.notna(x) else False
    )]['Question'].tolist()

    if related:
        suggested_q = random.choice(related)
        state["last_suggested_question"] = suggested_q
        return f"\n\nğŸ’¡ ØªØ­Ø¨ ØªØ¹Ø±Ù: {suggested_q}ØŸ (Ø¬Ø§ÙˆØ¨ Ø¨Ù€ Ù†Ø¹Ù… Ø£Ùˆ Ø§ÙŠ)"
    return ""


# ============================
# â­ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…ØµØ­Ø­Ø©
# ============================
def chatbot_response(user_input, state):
    cleaned = clean_text(user_input)
    dept_name = get_department_from_text(user_input)

    # ğŸ”¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ ÙˆÙ…Ø³Ø­ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­ Ø§Ù„Ù‚Ø¯ÙŠÙ…
    if dept_name:
        if dept_name != state["active_department"]:
            state["active_department"] = dept_name
            state["last_suggested_question"] = None

    # Ø¥Ø°Ø§ ÙˆØ§ÙÙ‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ù‚ØªØ±Ø­
    if state["last_suggested_question"] and any(word in cleaned for word in ["Ù†Ø¹Ù…", "Ø§ÙŠ", "Ø£ÙƒÙŠØ¯", "Ø·Ø¨Ø¹Ø§"]):
        match = get_close_matches(
            clean_text(state["last_suggested_question"]),
            df_training['Clean_Question'],
            n=1,
            cutoff=0.6
        )
        state["last_suggested_question"] = None
        if match:
            return df_training[df_training['Clean_Question'] == match[0]]['Answer'].values[0]
        else:
            return "âŒ Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„."

    # ===============================
    # ğŸ§  ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø°ÙƒÙŠ
    # ===============================
    if any(word in cleaned for word in [
        "Ø§Ø®ØªÙŠØ§Ø± Ø°ÙƒÙŠ", "Ø§Ø®ØªØ§Ø± Ù„ÙŠ", "Ø³Ø§Ø¹Ø¯Ù†ÙŠ Ø§Ø®ØªØ§Ø±", "Ø§Ø®ØªØ§Ø± Ù‚Ø³Ù…", "Ø§Ø±ÙŠØ¯ Ø§Ø®ØªØ§Ø± Ù‚Ø³Ù…",
        "Ø³Ø§Ø¹Ø¯Ù†ÙŠ ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù‚Ø³Ù…", "Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±", "Ø´Ù†Ùˆ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨",
        "Ø´Ù†Ùˆ Ø§Ø®ØªØ§Ø±", "Ø§Ù‚ØªØ±Ø­ Ù‚Ø³Ù…", "Ø£Ø±ÙŠØ¯ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù‚Ø³Ù…", "Ø§Ù‚ØªØ±Ø­ Ù„ÙŠ Ù‚Ø³Ù…",
        "Ø§Ø®ØªÙŠØ§Ø± Ù‚Ø³Ù…", "Ø§Ø®ØªØ± Ù„ÙŠ Ù‚Ø³Ù…"
    ]):
        state["smart_mode"] = True
        state["user_profile"] = {}
        return ("Ø®Ù„ÙŠÙ†Ø§ Ù†Ø®ØªØ§Ø± Ø£ÙØ¶Ù„ Ù‚Ø³Ù…ÙŠÙ† Ù„Ùƒ Ø®Ø·ÙˆØ© Ø®Ø·ÙˆØ© ğŸ‘‡\n"
                "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„:\n"
                "ØªØ­Ø¨ Ø£ÙƒØ«Ø±:\n"
                "1ï¸âƒ£ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© ÙˆØ§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ\n"
                "2ï¸âƒ£ Ø§Ù„ØªØµÙ…ÙŠÙ… ÙˆØ§Ù„Ø±Ø³Ù…\n"
                "3ï¸âƒ£ Ø§Ù„Ø´Ø¨ÙƒØ§Øª ÙˆØ§Ù„Ø­Ù…Ø§ÙŠØ©\n"
                "4ï¸âƒ£ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„\n"
                "5ï¸âƒ£ Ø§Ù„Ø¹Ù…Ø§Ø±Ø© ÙˆØ§Ù„Ø¨Ù†Ø§Ø¡\n"
                "Ø§ÙƒØªØ¨ Ø§Ù„Ø±Ù‚Ù… Ø£Ùˆ Ø§Ù„ÙˆØµÙ")

    # ===============================
    # ğŸ§  Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø°ÙƒÙŠ
    # ===============================
    if state["smart_mode"]:
        # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª
        if "interest" not in state["user_profile"]:
            interests_map = {
                "1": "programming", "Ø¨Ø±Ù…Ø¬Ø©": "programming",
                "2": "design", "ØªØµÙ…ÙŠÙ…": "design", "Ø±Ø³Ù…": "design",
                "3": "security", "Ø´Ø¨ÙƒØ§Øª": "security", "Ø­Ù…Ø§ÙŠØ©": "security",
                "4": "math", "Ø±ÙŠØ§Ø¶ÙŠØ§Øª": "math", "ØªØ­Ù„ÙŠÙ„": "math",
                "5": "architecture", "Ø¹Ù…Ø§Ø±Ø©": "architecture", "Ø¨Ù†Ø§Ø¡": "architecture"
            }
            for key, value in interests_map.items():
                if key in cleaned:
                    state["user_profile"]["interest"] = value
                    break

            if "interest" not in state["user_profile"]:
                return "Ø¬Ø§ÙˆØ¨Ù†ÙŠ: ØªØ­Ø¨ Ø¨Ø±Ù…Ø¬Ø©ØŒ ØªØµÙ…ÙŠÙ…ØŒ Ø´Ø¨ÙƒØ§ØªØŒ Ø±ÙŠØ§Ø¶ÙŠØ§ØªØŒ Ø£Ùˆ Ø¹Ù…Ø§Ø±Ø©ØŸ"

            return ("Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ:\n"
                    "ØªÙØ¶Ù„ Ø§Ù„Ø¯Ø±Ø§Ø³Ø© ØªÙƒÙˆÙ†:\n"
                    "1ï¸âƒ£ Ø¹Ù…Ù„ÙŠØ© (ØªØ·Ø¨ÙŠÙ‚ ÙˆÙ…Ø´Ø§Ø±ÙŠØ¹)\n"
                    "2ï¸âƒ£ Ù†Ø¸Ø±ÙŠØ© (ØªØ­Ù„ÙŠÙ„ ÙˆØ¯Ø±Ø§Ø³Ø©)\n"
                    "Ø§ÙƒØªØ¨ 1 Ø£Ùˆ 2")

        # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ù†ÙˆØ¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©
        elif "study_type" not in state["user_profile"]:
            if "1" in cleaned or "Ø¹Ù…Ù„ÙŠ" in cleaned:
                state["user_profile"]["study_type"] = "practical"
            elif "2" in cleaned or "Ù†Ø¸Ø±ÙŠ" in cleaned:
                state["user_profile"]["study_type"] = "theoretical"
            else:
                return "Ø¬Ø§ÙˆØ¨Ù†ÙŠ: ØªÙØ¶Ù„ Ø¹Ù…Ù„ÙŠ Ù„Ùˆ Ù†Ø¸Ø±ÙŠØŸ"

            return ("Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù„Ø«:\n"
                    "ØªØ­Ø¨ ØªØ´ØªØºÙ„ Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹ Ø£ÙƒØ«Ø± Ù…Ø¹:\n"
                    "1ï¸âƒ£ Ø£Ø¬Ù‡Ø²Ø© ÙˆØ£Ù†Ø¸Ù…Ø©\n"
                    "2ï¸âƒ£ Ø¨Ø±Ø§Ù…Ø¬ ÙˆØªØ·Ø¨ÙŠÙ‚Ø§Øª\n"
                    "3ï¸âƒ£ ØªØµØ§Ù…ÙŠÙ… ÙˆÙˆØ§Ø¬Ù‡Ø§Øª\n"
                    "Ø§ÙƒØªØ¨ Ø§Ù„Ø±Ù‚Ù…")

        # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù„Ø«: Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù…Ù„
        elif "work_type" not in state["user_profile"]:
            if "1" in cleaned:
                state["user_profile"]["work_type"] = "hardware"
            elif "2" in cleaned:
                state["user_profile"]["work_type"] = "software"
            elif "3" in cleaned:
                state["user_profile"]["work_type"] = "design"
            else:
                return "Ø¬Ø§ÙˆØ¨Ù†ÙŠ: 1 Ø£Ø¬Ù‡Ø²Ø©ØŒ 2 Ø¨Ø±Ø§Ù…Ø¬ØŒ 3 ØªØµÙ…ÙŠÙ…ØŸ"

            state["smart_mode"] = False
            interest = state["user_profile"]["interest"]
            work = state["user_profile"]["work_type"]
            recommendations = []

            if interest == "programming":
                if work == "software":
                    recommendations = ["Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©"]
                else:
                    recommendations = ["Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©", "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ"]
            elif interest == "design":
                recommendations = ["Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠ", "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¹Ù…Ø§Ø±Ø©"]
            elif interest == "security":
                recommendations = ["Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©"]
            elif interest == "math":
                recommendations = ["Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©"]
            elif interest == "architecture":
                recommendations = ["Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¹Ù…Ø§Ø±Ø©", "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠ"]

            state["user_profile"]["recommended"] = recommendations
            return ("Ø£ÙØ¶Ù„ Ù‚Ø³Ù…ÙŠÙ† Ù„Ùƒ Ù‡Ù…Ø§ ğŸ“:\n" + " Ùˆ ".join(recommendations))

    # ===============================
    # â“ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
    # ===============================

    if any(word in cleaned for word in ["Ù‚Ø³Ø· ", "Ù…Ø¨Ù„Øº", "Ù…Ø§Ù„", "ÙÙ„ÙˆØ³"]):
        if not dept_name:
            return "Ø±Ø¬Ø§Ø¡Ù‹ Ø­Ø¯Ù‘Ø¯ Ø§Ù„Ù‚Ø³Ù… Ø­ØªÙ‰ Ø£Ø­Ø³Ø¨ Ù„Ùƒ Ø§Ù„Ù‚Ø³Ø·."
        info = get_department_info(dept_name)
        if info is None:
            return "Ù…Ø§ Ù„Ù‚ÙŠØª Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù…."

        gpa_match = re.search(r'\d+', cleaned)
        suggestion = get_random_suggestion(dept_name, df_training, state)

        if gpa_match:
            gpa = int(gpa_match.group())
            if gpa >= 85:
                return f"Ø§Ù„Ù‚Ø³Ø· ÙÙŠ {dept_name} Ù‡Ùˆ {info['Fee_Above_85']} ğŸ’µ{suggestion}"
            else:
                return f"Ø§Ù„Ù‚Ø³Ø· ÙÙŠ {dept_name} Ù‡Ùˆ {info['Fee_Below_85']} ğŸ’µ{suggestion}"
        else:
            return (f"Ø§Ù„Ù‚Ø³Ø· ÙÙŠ {dept_name} Ø­Ø³Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©:\n"
                    f"Ø¥Ø°Ø§ Ù…Ø¹Ø¯Ù„Ùƒ 85 Ø£Ùˆ Ø£ÙƒØ«Ø±: {info['Fee_Above_85']}\n"
                    f"Ø¥Ø°Ø§ Ù…Ø¹Ø¯Ù„Ùƒ Ø£Ù‚Ù„ Ù…Ù† 85: {info['Fee_Below_85']}"
                    f"{suggestion}")

    elif any(word in cleaned for word in [
        "Ù…Ù‡Ø§Ø±Ø§Øª", "Ù…ÙˆØ§Ø¯", "Ù…Ù‚Ø±Ø±Ø§Øª", "Ø¯ÙˆØ±Ø§Øª", "Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©",
        "Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", "Ø§Ù„ÙƒÙˆØ±Ø³Ø§Øª", "Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©"
    ]):
        if dept_name:
            info = get_department_info(dept_name)
            suggestion = get_random_suggestion(dept_name, df_training, state)
            return (f"{dept_name}:\nØ§Ù„Ù…Ù‡Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ§Ø¯:\n{info['Key_Courses']}{suggestion}")
        else:
            return "Ø±Ø¬Ø§Ø¡Ù‹ Ø­Ø¯Ù‘Ø¯ Ø§Ù„Ù‚Ø³Ù… Ø­ØªÙ‰ Ø£Ø¹Ø·ÙŠÙƒ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ§Ø¯."

    else:
        match = get_close_matches(cleaned, df_training['Clean_Question'], n=1, cutoff=0.5)
        if match:
            return df_training[df_training['Clean_Question'] == match[0]]['Answer'].values[0]

        return "Ù…Ø§ ÙÙ‡Ù…Øª Ù‚ØµØ¯Ùƒ ØªÙ…Ø§Ù…Ø§Ù‹ØŒ ØªÙƒØ¯Ø± ØªØ³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ù…Ù‡Ø§Ø±Ø§Øª Ù‚Ø³Ù… Ù…Ø¹ÙŠÙ† Ø£Ùˆ Ø§Ù„Ù‚Ø³Ø· Ø£Ùˆ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø£Ù‚Ø³Ø§Ù…."
